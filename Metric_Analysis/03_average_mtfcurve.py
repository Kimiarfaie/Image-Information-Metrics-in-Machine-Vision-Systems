import os
import json
import numpy as np
import re
from glob import glob

'''
Script 03:
    This script averages MTF (Modulation Transfer Function) curves across multiple Imatest summary JSON files.

    MTF curves are vectors sampled at different frequency points for each image.
    Therefore, before averaging, all curves must be interpolated to a common frequency grid.
    This is necessary as each image may have MTF values sampled at different frequencies.

Input:
    - Directory of *_summary.json files generated by Imatest
    - One or more keywords to select a subset of the dataset (e.g., "100ISO", "-1EV")

Output:
    - A JSON file containing averaged MTF curves (mean + std) for each channel (R, G, B, Y) in an "Average" output folder.

Usage:
    python 03_average_mtfcurve.py
'''
def normalize(s):
    """Remove all non-alphanumeric characters and lowercase the string.
    Used to make filename keyword matching robust.
    """
    return re.sub(r"[^a-zA-Z0-9]", "", s).lower()

def interpolate_vectors(freq_lists, vec_lists, target_freq):
    """
    Interpolate multiple MTF curves to a shared target frequency grid.
    
    Args:
        freq_lists: list of arrays, each containing the frequency sampling of one image.
        vec_lists: list of arrays, each containing MTF values corresponding to freq_lists.
        target_freq: 1D numpy array of frequencies to interpolate onto.
    
    Returns:
        stacked 2D numpy array of interpolated MTF curves (N_images x N_freq_points)
    """
    interpolated = []
    for freq, vec in zip(freq_lists, vec_lists):
        if len(freq) == len(vec) and len(freq) > 1:
            interp = np.interp(target_freq, freq, vec)
            interpolated.append(interp)
    return np.stack(interpolated)

def average_summary_metrics(summary_dir, split_keywords, output_path, mapping_file=None):
    """
        Average MTF curves across multiple JSON files that match given keywords.
    """
    if isinstance(split_keywords, str):
        split_keywords = [split_keywords]

    normalized_keywords = [normalize(kw) for kw in split_keywords]
    all_files = glob(os.path.join(summary_dir, "*_summary.json"))

    filtered_files = []
    for f in all_files:
        fname = os.path.basename(f)
        norm_fname = normalize(fname)
        if all(nkw in norm_fname for nkw in normalized_keywords):
            filtered_files.append(f)

    for f in filtered_files:
        print("  âž”", os.path.basename(f))

    if not filtered_files:
        print("No matching summary files. Double-check keyword formats.")
        return

    metrics = {
        "mtf_r": [], "mtf_g": [], "mtf_b": [],
        "mtf_y": []
    }

    x_axis_fields = {
        "freq1": None, "freq1units": None,
        "all_freq1": []
    }

    for file in filtered_files:
        with open(file, 'r') as f:
            data = json.load(f)

        mtf_plot = data.get("mtf_plot", {})

        # Vector MTF curves
        for key in ["mtf_r", "mtf_g", "mtf_b", "mtf_y"]:
            vec = mtf_plot.get(key)
            if vec:
                metrics[key].append(vec)

        freq1 = mtf_plot.get("freq1", [])
        if freq1:
            x_axis_fields["all_freq1"].append(freq1)

        if x_axis_fields["freq1units"] is None:
            x_axis_fields["freq1units"] = mtf_plot.get("freq1units", "")

    # === Averaging ===
    result = {}

    # Interpolate and average MTF curves
    target_freq = np.linspace(0, 1.0, 100)
    freq_lists = x_axis_fields["all_freq1"]
    for key in ["mtf_r", "mtf_g", "mtf_b", "mtf_y"]:
        vecs = metrics[key]
        if vecs and freq_lists and len(vecs) == len(freq_lists):
            stacked = interpolate_vectors(freq_lists, vecs, target_freq)
            avg = np.mean(stacked, axis=0)
            std = np.std(stacked, axis=0)
            result[key] = avg.tolist()
            result[f"{key}_std"] = std.tolist()

    result["freq1"] = target_freq.tolist()
    result["freq1units"] = x_axis_fields["freq1units"]

    # === Save ===
    os.makedirs(output_path, exist_ok=True)
    split_name = "_AND_".join([kw.replace(" ", "").replace(".", ".") for kw in split_keywords])
    output_file = os.path.join(output_path, f"{split_name}_average_summary.json")

    with open(output_file, 'w') as f:
        json.dump(result, f, indent=4)

    print(f"Saved average summary to: {output_file}")

if __name__ == "__main__":
    summary_dir = "/Users/kimiaarfaie/Github/Image-Information-Metrics-in-Machine-Vision-Systems/Metric_Analysis/Metrics/Dataset/Extracted"
    keywords = ["-1EV"]  # Change these
    output_dir = "/Users/kimiaarfaie/Github/Image-Information-Metrics-in-Machine-Vision-Systems/Metric_Analysis/Metrics/Dataset/Average Metrics"

    average_summary_metrics(summary_dir, keywords, output_dir)
